{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c8388d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Setup complete\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "load_dotenv()\n",
    "print(\"✅ Setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb4e75e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Added 3 documents\n",
      "\n",
      "Search Results:\n",
      "1. Python is a programming language\n",
      "2. Machine learning uses algorithms\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "# from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# Initialize\n",
    "# embeddings = GoogleGenerativeAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/gemini-embedding-001\")\n",
    "vector_store = InMemoryVectorStore(embedding=embeddings)\n",
    "\n",
    "# Add documents\n",
    "docs = [\n",
    "    Document(page_content=\"Python is a programming language\"),\n",
    "    Document(page_content=\"Machine learning uses algorithms\"),\n",
    "    Document(page_content=\"The sun is a star\")\n",
    "]\n",
    "\n",
    "vector_store.add_documents(docs)\n",
    "print(f\"✅ Added {len(docs)} documents\\n\")\n",
    "\n",
    "# Search\n",
    "results = vector_store.similarity_search(\"What is Python?\", k=2)\n",
    "\n",
    "print(\"Search Results:\")\n",
    "for i, doc in enumerate(results, 1):\n",
    "    print(f\"{i}. {doc.page_content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c9f4583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading PDF...\n",
      "Split into 52 chunks\n",
      "Creating embeddings (this may take a minute)...\n",
      "✅ FAISS index saved\n",
      "\n",
      "Query: What is attention mechanism?\n",
      "\n",
      "Result 1:\n",
      "  3.2 Attention\n",
      "An attention function can be described as mapping a query and a set of key-value pairs to an output,\n",
      "where the query, keys, values, and ...\n",
      "\n",
      "Result 2:\n",
      "  Scaled Dot-Product Attention\n",
      " Multi-Head Attention\n",
      "Figure 2: (left) Scaled Dot-Product Attention. (right) Multi-Head Attention consists of several\n",
      "att...\n",
      "\n",
      "Result 3:\n",
      "  The Transformer uses multi-head attention in three different ways:\n",
      "• In \"encoder-decoder attention\" layers, the queries come from the previous decoder...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from pathlib import Path\n",
    "\n",
    "# Load and split a PDF\n",
    "pdf_path = \"attention.pdf\"\n",
    "\n",
    "if Path(pdf_path).exists():\n",
    "    print(\"Loading PDF...\")\n",
    "    loader = PyPDFLoader(pdf_path)\n",
    "    documents = loader.load()\n",
    "    \n",
    "    # Split\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=200\n",
    "    )\n",
    "    chunks = splitter.split_documents(documents)\n",
    "    print(f\"Split into {len(chunks)} chunks\")\n",
    "    \n",
    "    # Create FAISS vectorstore\n",
    "    print(\"Creating embeddings (this may take a minute)...\")\n",
    "    vectorstore = FAISS.from_documents(chunks, embeddings)\n",
    "    \n",
    "    # Save to disk\n",
    "    vectorstore.save_local(\"./faiss_index_notebook\")\n",
    "    print(\"✅ FAISS index saved\\n\")\n",
    "    \n",
    "    # Search\n",
    "    query = \"What is attention mechanism?\"\n",
    "    results = vectorstore.similarity_search(query, k=3)\n",
    "    \n",
    "    print(f\"Query: {query}\\n\")\n",
    "    for i, doc in enumerate(results, 1):\n",
    "        print(f\"Result {i}:\")\n",
    "        print(f\"  {doc.page_content[:150]}...\\n\")\n",
    "else:\n",
    "    print(f\"❌ PDF not found: {pdf_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aff6b5ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded existing FAISS index\n",
      "\n",
      "Found 2 results\n"
     ]
    }
   ],
   "source": [
    "# Load existing index\n",
    "if Path(\"./faiss_index_notebook\").exists():\n",
    "    loaded_vectorstore = FAISS.load_local(\n",
    "        \"./faiss_index_notebook\",\n",
    "        embeddings,\n",
    "        allow_dangerous_deserialization=True\n",
    "    )\n",
    "    print(\"✅ Loaded existing FAISS index\")\n",
    "    \n",
    "    # Use it\n",
    "    results = loaded_vectorstore.similarity_search(\"transformers\", k=2)\n",
    "    print(f\"\\nFound {len(results)} results\")\n",
    "else:\n",
    "    print(\"No existing index found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb9dc993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='4c88f6e9-67e9-4fab-add0-144ff8ef2ba5', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 2, 'page_label': '3'}, page_content='Figure 1: The Transformer - model architecture.\\nThe Transformer follows this overall architecture using stacked self-attention and point-wise, fully\\nconnected layers for both the encoder and decoder, shown in the left and right halves of Figure 1,\\nrespectively.\\n3.1 Encoder and Decoder Stacks\\nEncoder: The encoder is composed of a stack of N = 6 identical layers. Each layer has two\\nsub-layers. The first is a multi-head self-attention mechanism, and the second is a simple, position-\\nwise fully connected feed-forward network. We employ a residual connection [11] around each of\\nthe two sub-layers, followed by layer normalization [ 1]. That is, the output of each sub-layer is\\nLayerNorm(x + Sublayer(x)), where Sublayer(x) is the function implemented by the sub-layer\\nitself. To facilitate these residual connections, all sub-layers in the model, as well as the embedding\\nlayers, produce outputs of dimension dmodel = 512.'),\n",
       " Document(id='d19b2091-04b6-435c-b92b-1fbc330154c3', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 1, 'page_label': '2'}, page_content='In this work we propose the Transformer, a model architecture eschewing recurrence and instead\\nrelying entirely on an attention mechanism to draw global dependencies between input and output.\\nThe Transformer allows for significantly more parallelization and can reach a new state of the art in\\ntranslation quality after being trained for as little as twelve hours on eight P100 GPUs.\\n2 Background\\nThe goal of reducing sequential computation also forms the foundation of the Extended Neural GPU\\n[16], ByteNet [18] and ConvS2S [9], all of which use convolutional neural networks as basic building\\nblock, computing hidden representations in parallel for all input and output positions. In these models,\\nthe number of operations required to relate signals from two arbitrary input or output positions grows\\nin the distance between positions, linearly for ConvS2S and logarithmically for ByteNet. This makes')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bc85367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Added documents to Chroma\n",
      "\n",
      "Filtered search results:\n",
      "  RAG combines retrieval and generation\n",
      "  Metadata: {'difficulty': 'intermediate', 'topic': 'rag'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "# Create Chroma vectorstore\n",
    "chroma_store = Chroma(\n",
    "    collection_name=\"my_collection\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"./chroma_db_notebook\"\n",
    ")\n",
    "\n",
    "# Add documents\n",
    "sample_docs = [\n",
    "    Document(\n",
    "        page_content=\"RAG combines retrieval and generation\",\n",
    "        metadata={\"topic\": \"rag\", \"difficulty\": \"intermediate\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"LangChain simplifies LLM applications\",\n",
    "        metadata={\"topic\": \"langchain\", \"difficulty\": \"beginner\"}\n",
    "    )\n",
    "]\n",
    "\n",
    "chroma_store.add_documents(sample_docs)\n",
    "print(\"✅ Added documents to Chroma\\n\")\n",
    "\n",
    "# Search with metadata filter\n",
    "results = chroma_store.similarity_search(\n",
    "    \"Tell me about RAG\",\n",
    "    k=2,\n",
    "    filter={\"topic\": \"rag\"}\n",
    ")\n",
    "\n",
    "print(\"Filtered search results:\")\n",
    "for doc in results:\n",
    "    print(f\"  {doc.page_content}\")\n",
    "    print(f\"  Metadata: {doc.metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a184ef1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
